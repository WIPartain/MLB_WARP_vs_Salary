{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 99.0.4844\n",
      "Get LATEST chromedriver version for 99.0.4844 google-chrome\n",
      "Driver [C:\\Users\\taher\\.wdm\\drivers\\chromedriver\\win32\\99.0.4844.51\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "#Initializes Chrome web driver\n",
    "\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapes the site by nesting the year in the team for loop to iterate through year 2000-2020 first,\n",
    "#then change teams when counter reaches 2021\n",
    "\n",
    "def team_salary():\n",
    "    \n",
    "    #set teams up as dictionary to access the key for the url input\n",
    "    #and the access the value for df legibility\n",
    "    teams = {'ANA':'Angels','ARI':'Diamondbacks','ATL':'Braves','BAL':'Orioles','BOS':'Red Sox',\n",
    "    'CHN':'Cubs','CHA':'White Sox','CIN':'Reds','CLE':'Indians','COL':'Rockies','DET':'Tigers',\n",
    "    'HOU':'Astros','KCA':'Royals','LAN':'Dodgers','MIA':'Marlins','MIL':'Brewers','MIN':'Twins',\n",
    "    'NYN':'Mets','NYA':'Yankees','OAK':'Athletics','PHI':'Phillies','PIT':'Pirates','SDN':'Padres',\n",
    "    'SFN':'Giants','SEA':'Mariners','SLN':'Cardinals','TBA':'Rays','TEX':'Rangers','TOR':'Blue Jays','WAS':'Nationals'}\n",
    "    data2 = []\n",
    "    \n",
    "    for key,value in teams.items():\n",
    "        for year in range(2000,2021):\n",
    "            \n",
    "            #Try/Except AttributeError to prevent break if url doesn't exist for a specific year\n",
    "            try:\n",
    "                url = f'https://legacy.baseballprospectus.com/compensation/index.php?team={key}&cyear={year}'\n",
    "                browser.visit(url)\n",
    "                browser.is_element_present_by_css('div.dataTables_wrapper',wait_time = 1)\n",
    "                html = browser.html\n",
    "                html_soup = soup(html,'html.parser')\n",
    "\n",
    "                #finds the table in the HTML containing the player salary information\n",
    "                table = html_soup.find('table',attrs={'id' : 'cotsplayers_datagrid'})\n",
    "                t_body = table.find('tbody')\n",
    "                rows = t_body.find_all('tr')\n",
    "\n",
    "                #retrieves data from the entire table \n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')\n",
    "                    cols = [ele.text.strip() for ele in cols]\n",
    "                    #removes the last column (un-needed and throws off list length and triggers error when input into df)\n",
    "                    cols = cols[:-1]\n",
    "\n",
    "                    cols.append(value)\n",
    "                    cols.append(year)\n",
    "                    data2.append([ele for ele in cols if ele])\n",
    "\n",
    "                    \n",
    "\n",
    "            except AttributeError:\n",
    "                print(f'No web page exists for {value} in {year}')\n",
    "\n",
    "    df =  pd.DataFrame(data = data2, columns = [\"Player\", \"Pos\", \"Salary\", \"Pct\", \"WARP\", \"WARP/$M\", \"$/WARP\",\"TEAM\",\"YEAR\"])\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No web page exists for Marlins in 2000\n",
      "No web page exists for Marlins in 2001\n",
      "No web page exists for Marlins in 2002\n",
      "No web page exists for Marlins in 2003\n",
      "No web page exists for Marlins in 2004\n",
      "No web page exists for Marlins in 2005\n",
      "No web page exists for Marlins in 2006\n",
      "No web page exists for Marlins in 2007\n",
      "No web page exists for Marlins in 2008\n",
      "No web page exists for Marlins in 2009\n",
      "No web page exists for Marlins in 2010\n",
      "No web page exists for Marlins in 2011\n",
      "No web page exists for Nationals in 2000\n",
      "No web page exists for Nationals in 2001\n",
      "No web page exists for Nationals in 2002\n",
      "No web page exists for Nationals in 2003\n",
      "No web page exists for Nationals in 2004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "team_salary().to_csv('player_salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapes the team's payroll using similar process in the team_salary() function\n",
    "\n",
    "def payroll():\n",
    "    teams = {'ANA':'Angels','ARI':'Diamondbacks','ATL':'Braves','BAL':'Orioles','BOS':'Red Sox',\n",
    "    'CHN':'Cubs','CHA':'White Sox','CIN':'Reds','CLE':'Indians','COL':'Rockies','DET':'Tigers',\n",
    "    'HOU':'Astros','KCA':'Royals','LAN':'Dodgers','MIA':'Marlins','MIL':'Brewers','MIN':'Twins',\n",
    "    'NYN':'Mets','NYA':'Yankees','OAK':'Athletics','PHI':'Phillies','PIT':'Pirates','SDN':'Padres',\n",
    "    'SFN':'Giants','SEA':'Mariners','SLN':'Cardinals','TBA':'Rays','TEX':'Rangers','TOR':'Blue Jays','WAS':'Nationals'}\n",
    "    team_data = []\n",
    "    \n",
    "    for key,value in teams.items():\n",
    "        url = f'https://legacy.baseballprospectus.com/compensation/index.php?team={key}&cyear=2019'\n",
    "        browser.visit(url)\n",
    "        browser.is_element_present_by_css('div.dataTables_wrapper',wait_time = 1)\n",
    "        html = browser.html\n",
    "        html_soup = soup(html,'html.parser')\n",
    "\n",
    "        #finds the franchise payroll table in the HTML\n",
    "        team_payroll_table = html_soup.find('table',attrs={'id':'cotspayroll_datagrid'})\n",
    "        table_body = team_payroll_table.find('tbody')\n",
    "        rows = table_body.find_all('tr')\n",
    "        \n",
    "\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            cols.append(value)\n",
    "            team_data.append([ele for ele in cols if ele])\n",
    "\n",
    "\n",
    "    df =  pd.DataFrame(data = team_data, columns = [\"Year\",\"Team Payroll\", \"Avg Payroll\",\"Diff\",'Team'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "payroll().to_csv('team_payrolls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
